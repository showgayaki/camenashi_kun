{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcjSRFELVbNk"
   },
   "source": [
    "# Train Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mmaction2をimportできるようにPATHを通しておく\n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path().resolve()\n",
    "root_dir = current_dir.parents[1]\n",
    "mmaction2_dir = root_dir.joinpath('mmaction2')\n",
    "\n",
    "if not (f'{root_dir}' in sys.path and f'{mmaction2_dir}' in sys.path):\n",
    "    sys.path.append(f'{root_dir}')\n",
    "    sys.path.append(f'{mmaction2_dir}')\n",
    "    sys.path\n",
    "else:\n",
    "    print(f'[{root_dir}] and [{mmaction2_dir}] directories are alreardy registerd.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mmaction2をclone\n",
    "(Apple silicon使用の場合は、dtypeを変更する)\n",
    "\"\"\"\n",
    "if not mmaction2_dir.is_dir():\n",
    "    # Install mmaction2\n",
    "    %cd {root_dir}\n",
    "    !git clone https://github.com/open-mmlab/mmaction2.git -b main\n",
    "    %pip install -U openmim\n",
    "    !mim install mmengine\n",
    "    !mim install mmcv\n",
    "    !mim install mmdet\n",
    "\n",
    "    # Cannot convert a MPS Tensor to float64 dtype as the MPS framework doesn't support float64. Please use float32 instead.\n",
    "    # のエラー対応\n",
    "    import torch\n",
    "    if torch.backends.mps.is_available():\n",
    "        !sed -i \"\" s/\"a, device=cls_scores.device)\"/\"a, device=cls_scores.device, dtype=torch.float32)\"/g {mmaction2_dir}/mmaction/models/heads/base.py\n",
    "    %cd {current_dir}\n",
    "else:\n",
    "    print(f'[{mmaction2_dir}] directory is already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "No_zZAFpWC-a",
    "outputId": "9386dd81-2308-4adb-d3cb-798de11c035e"
   },
   "outputs": [],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMAction2 installation\n",
    "from mmaction2 import mmaction\n",
    "print(mmaction.__version__)\n",
    "\n",
    "# Check MMCV installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "# Check MMEngine installation\n",
    "from mmengine.utils.dl_utils import collect_env\n",
    "print(collect_env())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTdi6dI0hY3g",
    "outputId": "95f22438-566c-4496-fe0c-50e128b47b5e"
   },
   "outputs": [],
   "source": [
    "# After downloading the data, we need to check the annotation format\n",
    "!cat data/toilet/toilet_train_video.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ht_DGJA9jQar"
   },
   "source": [
    "### Modify the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjCcmCKOjktc"
   },
   "outputs": [],
   "source": [
    "from mmaction2.mmaction.apis import inference_recognizer, init_recognizer\n",
    "from mmengine import Config\n",
    "from mmengine.runner import set_random_seed\n",
    "\n",
    "\n",
    "cfg = Config.fromfile('./config/toilet_config.py')\n",
    "\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = None\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = 'checkpoint/toilet'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.train_dataloader.batch_size = cfg.train_dataloader.batch_size // 16\n",
    "cfg.val_dataloader.batch_size = cfg.val_dataloader.batch_size // 16\n",
    "cfg.optim_wrapper.optimizer.lr = cfg.optim_wrapper.optimizer.lr / 8 / 16\n",
    "cfg.train_cfg.max_epochs = 10\n",
    "\n",
    "cfg.train_dataloader.num_workers = 2\n",
    "cfg.val_dataloader.num_workers = 2\n",
    "cfg.test_dataloader.num_workers = 2\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tES-qnZ3k38Z"
   },
   "source": [
    "### Train a new recognizer\n",
    "\n",
    "Finally, lets initialize the dataset and recognizer, then train a new recognizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDBWkdDRk6oz",
    "outputId": "044b9e09-2038-41c9-d5a3-8a74ae11ade2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import mmengine\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "\n",
    "# Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend\n",
    "# 上記エラーの回避\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.device('mps')\n",
    "\n",
    "# Create work_dir\n",
    "mmengine.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "# build the runner from config\n",
    "runner = Runner.from_cfg(cfg)\n",
    "\n",
    "# start training\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryVoSfZVmogw"
   },
   "source": [
    "## Test the trained recognizer\n",
    "\n",
    "After finetuning the recognizer, let's check the prediction results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "34fbbdc5-b9fd-4fd2-8030-3ba56b10adbf"
   },
   "outputs": [],
   "source": [
    "runner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {root_dir}\n",
    "!PYTHONPATH=mmaction2 python mmaction2/demo/demo.py --device mps camenashi_kun/classification/config/toilet_config.py \\\n",
    "    camenashi_kun/classification/checkpoint/toilet/epoch_9.pth \\\n",
    "    camenashi_kun/classification/data/toilet/val/20240213-105939.mp4 camenashi_kun/classification/data/toilet/label_map.txt"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mmact_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "189c342a4747645665e89db23000ac4d4edb7a87c4cd0b2f881610f468fb778d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
